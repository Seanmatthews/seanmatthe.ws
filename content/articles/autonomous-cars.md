---
title: "Keep Your Hands On The Wheel"
date: 2019-04-21T16:29:19-04:00
draft: true
type: articles
---

Autonomous cars are a topic about which my industry friends and I talk at length, and typically, with an amount of disbelief that might surprise some. Before you write me off as a jealous armchair cynic that poo-poos technologies or successes with which I'm not involved, let me preface this piece with my experiences. Over the past 12 years, I have worked professionally with all sorts autonomous robots, specifically designing and developing high level behaviors in complex environments-- weaponized military robots, industrial mining robots, academic robots, aerial robots, ground robots, underwater robots. I beleive these experiences have afforded me an amount of expertise to where I can speak as an authority on the viability of the application of robotics technologies to solve real-world problems. And standing on this platform, to the chagrin of investors, I proclaim that autonomous car technology has *at least* of decade of work ahead of it before commercial viability.


## Autonomous Cars Are Effectively Blind
Sensors have come a long way, but remain incredibly uncertain in their measurements. Examples and basis for this?
## Constrain The Problem Space
We can greatly increase the velocity toward commerical viability of autonomous cars if we severely limit the problem space. 
- low speeds
- on specially designed roads
- disallowing manual cars in the area
## Public Perception
It doesn't matter if they kill far less than human drivers. People expect AI to be perfect.
### Codifying the trolley problem
Except where gross negligence was to blame, We call it a "traffic accident" when a human driver causes death with a vehicle. But up until the point of the incident, and at each point during the incident (however quick) the human brain controlling the body in the driver's seat was making decisions. Referring to it as an accident accepts that, given that codifiably acceptable precaution was taken to prevent any possible incident, the driver was improbably thrust into a situation for which there was inadequate time to evaluate and respond properly. The dvier may have hit one person in order to avoid hitting five *as an unavoidable decision in the moment". On the other hand, when a computer controls the car, some developers programmed the computer's response far ahead of the incident. How do you ethically create (and publicize) protocols for whom should die in car accidents?
### Who takes the blame?
In a typical traffic incident, one of the key decisions that occurs in the aftermath is to place blame on an involved party. This helps decide who pays damages, physical, mental, or emotional. We have painstakingly architected our current legal and insurance systems around this principle. What happens now when an autonomous car hits a pedestrian? How about when two autonomous cars collide? What if the autonomous cars are not owned by an individual, but a company? You can quickly imagine how the responsibilty graph balloons to a size that runs the risk of diluting blame. 
